{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Guidelines\n",
    "\n",
    "The Capstone Project is a group project, which will be used in place of a Final Exam. Here are the guidelines for the project:\n",
    "\n",
    "## 1. Team Formation\n",
    "\n",
    "Form teams of 3-4 people.\n",
    "\n",
    "## 2. Dataset Selection\n",
    "\n",
    "Sign into Kaggle and select a dataset/competition that interests your team. There are many types of projects, some covering machine learning topics that we did not cover in class. However, you should be able to find projects in:\n",
    "\n",
    "1. Map/Reduce\n",
    "2. Linear Regression\n",
    "3. Logistic Regression\n",
    "4. Clustering\n",
    "\n",
    "You do not have to choose one of these, you can branch out if you want. Download the data from Kaggle. If you are using data from one of the competitions, sign up for the competition, download the data (then solve the problem and submit your results!).\n",
    "\n",
    "## 3. Approach\n",
    "\n",
    "Perform the suggested analysis, then report on your work. Describe the approach you took and the steps you took to clean the data, improve the results, etc.\n",
    "\n",
    "## 4. Results\n",
    "\n",
    "Report your results and visualize them using different graphs/charts/views to highlight your conclusions. Compare your results with other submissions to Kaggle, if that information is available.\n",
    "\n",
    "## 5. Conclusion\n",
    "\n",
    "Summarize what worked well and what did not work well.\n",
    "\n",
    "## Submission\n",
    "\n",
    "Submit a report indicating:\n",
    "\n",
    "1. Who is on your team\n",
    "2. Which dataset/competition you chose\n",
    "3. What approach you took. What steps did you take to clean the data, improve the results, etc.\n",
    "4. What are your results. How did you choose to visualize the results (perhaps show different graphs/charts/views to highlight your conclusions)\n",
    "5. How did your results compare (if that information is available)\n",
    "6. What worked well, what not so well.\n",
    "\n",
    "Since this is a group project, only one submission is needed for the group. Based on the list of names, the score will be copied to everyone in the group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the popularity of memes using clustering: SNAP Memetracker | Kaggle\n",
    "https://www.kaggle.com/datasets/snap/snap-memetracker\n",
    "\n",
    "We are going to use the SNAP Memetracker dataset to analyze the popularity of memes using clustering. \n",
    "We want to use the data to find out what memes are popular and what memes are not and the reasons why.\n",
    "We will find correlation between the popularity of memes and the number of times they are used in a day and the relationship between likes, dislikes, and comments.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         article_id  \\\n",
      "0                 1   \n",
      "1                 1   \n",
      "2                 1   \n",
      "3                 1   \n",
      "4                 7   \n",
      "...             ...   \n",
      "7956120     4542917   \n",
      "7956121     4542917   \n",
      "7956122     4542917   \n",
      "7956123     4542917   \n",
      "7956124     4542919   \n",
      "\n",
      "                                                                                                                                                                                                                                                              phrase  \n",
      "0                                                                            an emergency session of the general assembly has adopted the follwing sic emergency regulations to ease the load on local electorial sic precincts and ensure a fair electorial process  \n",
      "1                                                                                                                             we are sorry for any inconvenience this may cause but felt this was the only way to ensure fairness to the complete electorial process  \n",
      "2                                                                                                                                                                                        it's not even on our letterhead they just copied the logo from our web site  \n",
      "3                                                                                                                                                                                                                                                         look at me  \n",
      "4                                                                                                                                                                                                                                 make no mistake what this is about  \n",
      "...                                                                                                                                                                                                                                                              ...  \n",
      "7956120                                                                                                                                                                                              what i thought was beautiful doesn't live inside of you anymore  \n",
      "7956121  lots of acoustic flamenco guitars multi-layered vocals with dire straits style guitar solo breakdown oh no's very silent lucidity ish queensryche a moment when axl sings i don't want to do it makes everyone in the room look at each other startled urgh  \n",
      "7956122                                                                                                                          i won't be told any more that i've been brought down in this storm and left so far out from the shore that i can't find my way back  \n",
      "7956123                                                                                                                                                                                      why should i choose to prostitute myself to live with fortune and shame  \n",
      "7956124                                                                                                                                                                                                 this industry is in a crisis situation not of its own making  \n",
      "\n",
      "[7956125 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('database.sqlite')\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# Replace this with the code to read data from the quotes table\n",
    "df = pd.read_sql_query('SELECT * FROM quotes', conn)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         article_id                 date  \\\n",
      "0                 0  2008-11-01 00:00:06   \n",
      "1                 1  2008-11-01 00:00:06   \n",
      "2                 2  2008-11-01 00:00:06   \n",
      "3                 3  2008-11-01 00:00:06   \n",
      "4                 4  2008-11-01 00:00:06   \n",
      "...             ...                  ...   \n",
      "4542915     4542915  2008-11-15 23:59:57   \n",
      "4542916     4542916  2008-11-15 23:59:57   \n",
      "4542917     4542917  2008-11-15 23:59:58   \n",
      "4542918     4542918  2008-11-15 23:59:58   \n",
      "4542919     4542919  2008-11-15 23:59:59   \n",
      "\n",
      "                                                                                         url  \n",
      "0                                       http://forums.slickdeals.net/showthread.php?t=988781  \n",
      "1                                       http://forums.slickdeals.net/showthread.php?t=988773  \n",
      "2                                       http://forums.slickdeals.net/showthread.php?t=988771  \n",
      "3                                       http://forums.slickdeals.net/showthread.php?t=988785  \n",
      "4                                       http://forums.slickdeals.net/showthread.php?t=988761  \n",
      "...                                                                                      ...  \n",
      "4542915  http://fifa.com/worldfootball/clubfootball/news/newsid=947763.html?cid=rssfeed&att=  \n",
      "4542916                                            http://rssjunky.com/rssreview/189823.html  \n",
      "4542917                                          http://gnrdaily.com/news_detail.asp?id=1794  \n",
      "4542918   http://runestones.blogspot.com/2008/11/blues-break-toumani-diabate-elyne-road.html  \n",
      "4542919           http://online.wsj.com/article/sb122679146976431189.html?mod=googlenews_wsj  \n",
      "\n",
      "[4542920 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('database.sqlite')\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# Replace this with the code to read data from the quotes table\n",
    "df = pd.read_sql_query('SELECT * FROM articles', conn)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          article_id  \\\n",
      "0                  0   \n",
      "1                  1   \n",
      "2                  1   \n",
      "3                  2   \n",
      "4                  3   \n",
      "...              ...   \n",
      "16727120     4542918   \n",
      "16727121     4542918   \n",
      "16727122     4542918   \n",
      "16727123     4542918   \n",
      "16727124     4542919   \n",
      "\n",
      "                                                                                                                                                                                                                                                                              link_out  \\\n",
      "0                                                                                                                                                                        http://slickdeals.net/?sduid=442421&amp;sdtid=988781&amp;sdfid=9&amp;u2=http://shop1.frys.com/product/5636921   \n",
      "1                                                                                                                               http://slickdeals.net/?sduid=36723&amp;sdtid=988773&amp;sdfid=7&amp;u2=http://hamptonroads.com/2008/10/phony-flier-says-virginians-vote-different-days   \n",
      "2                                                                                                                                                                                                                          http://media.hamptonroads.com/cache/files/images/195911.jpg   \n",
      "3                                                                                                                                                                          http://slickdeals.net/?sduid=267353&amp;sdtid=988771&amp;sdfid=11&amp;u2=http://www.decorinnovaction.:wave:   \n",
      "4                                                                            http://slickdeals.net/?sduid=60460&amp;sdtid=988785&amp;sdfid=9&amp;u2=http://www.newegg.com/product/productcombos.aspx?item=n82e16817341012&amp;subcategory=7&amp;sortfield=0&amp;pagesize=10&amp;page=1   \n",
      "...                                                                                                                                                                                                                                                                                ...   \n",
      "16727120                                                                                                                                                                                                                           http://runestones.blogspot.com/search/label/diabate   \n",
      "16727121                                                                                                                                                                                                                     http://haloscan.com/comments/runeor88/2864281856811335401   \n",
      "16727122                                                                                                                                                                                                                           http://haloscan.com/tb/runeor88/2864281856811335401   \n",
      "16727123                                                                                                                                                                                                                                              http://runestones.blogspot.com/'   \n",
      "16727124  http://news.google.com/news?ned=:epkh8bm9e-lw4kzosu3ms0tntrhi1glpsezoti0qfhlseigoyixltk5uymwrss3ksy0rytdilcsski0wetustk7nk84vks7iledii2gj5wymf-ux56evkbsnjpcwzzzuwlxnjpd_wi_zqy_83tjprtjqkq3ycgc7qiyq/public/search?article-doc-type=%7bbusiness%7d&amp;header_text=business   \n",
      "\n",
      "          link_out_id  \n",
      "0                 NaN  \n",
      "1                 NaN  \n",
      "2                 NaN  \n",
      "3                 NaN  \n",
      "4                 NaN  \n",
      "...               ...  \n",
      "16727120          NaN  \n",
      "16727121          NaN  \n",
      "16727122          NaN  \n",
      "16727123          NaN  \n",
      "16727124          NaN  \n",
      "\n",
      "[16727125 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('database.sqlite')\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# Replace this with the code to read data from the quotes table\n",
    "df = pd.read_sql_query('SELECT * FROM links', conn)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the data into a format that can be used for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13932/3098153826.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create a TfidfVectorizer object to transform the phrases into vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TfidfVectorizer object to transform the phrases into vectors\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Transform the phrases into vectors\n",
    "vectors = vectorizer.fit_transform(quotes_df['phrase'])\n",
    "\n",
    "# Convert the vectors to a DataFrame\n",
    "vectors_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Print the first few rows of the DataFrame to check the data\n",
    "print(vectors_df.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Apply clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13932/422294237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create a KMeans object with 10 clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a KMeans object with 10 clusters\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "\n",
    "# Fit the model to the data\n",
    "kmeans.fit(vectors_df)\n",
    "\n",
    "# Get the cluster labels\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Add the labels to the quotes DataFrame\n",
    "quotes_df['cluster'] = labels\n",
    "\n",
    "# Print the first few rows of the DataFrame to check the data\n",
    "print(quotes_df.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of the clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of the cluster sizes\n",
    "plt.hist(quotes_df['cluster'], bins=10)\n",
    "plt.title('Distribution of cluster sizes')\n",
    "plt.xlabel('Cluster label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
